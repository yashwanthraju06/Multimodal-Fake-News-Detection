# Multimodal Fake News Detection ğŸ“°ğŸ§ 

This project focuses on **fake news detection using multimodal learning** â€” combining textual and visual information (text + image) to improve the accuracy of detecting misleading or fake content.

## ğŸ“Œ Project Description

Fake news spreads rapidly through social media, often leveraging emotionally charged text and misleading images. This project uses both **textual data** (article/title) and **visual data** (associated images) to train deep learning models for detecting fake news more effectively than unimodal approaches.

## ğŸ” Dataset

We use the **[Mirage-News dataset](https://huggingface.co/datasets/anson-huang/mirage-news)**:
- Contains real and fake news samples.
- Each sample includes:
  - `text`: News content or title.
  - `image`: Corresponding news image.
  - `label`: Ground truth (fake or real).

## ğŸ§  Models Implemented

- âœ… **CNN (Text-only)**
- âœ… **CNN (Text + Image)**
- âœ… **BERT + CNN (Text + Image)**
- âœ… **BiLSTM (Text-only)**
- âœ… **ResNet + BERT (Multimodal)**

## ğŸ›  Tech Stack

- **Python**
- **PyTorch**
- **Transformers (Hugging Face)**
- **TorchVision** (for image encoders like ResNet/VGG)
- **scikit-learn**
- **matplotlib / seaborn** (for plots & confusion matrices)

## ğŸ§ª Evaluation Metrics

- Accuracy
- Precision
- Recall
- F1-Score
- Confusion Matrix

## ğŸ” Secrets Management

The Hugging Face API token is **stored securely in a `.env` file** (not tracked by Git).  
**Ensure you create your `.env` with:**

```env
HF_TOKEN=your_huggingface_token_here
